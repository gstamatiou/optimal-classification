{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "a709d09f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a709d09f",
        "outputId": "8126d595-b8ef-41f9-b50c-46ef0e15dac1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: graphlearning in /usr/local/lib/python3.7/dist-packages (1.2.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from graphlearning) (3.2.2)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (from graphlearning) (0.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from graphlearning) (1.7.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from graphlearning) (1.21.6)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->graphlearning) (2.8.2)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->graphlearning) (3.0.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->graphlearning) (1.4.4)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->graphlearning) (0.11.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from kiwisolver>=1.0.1->matplotlib->graphlearning) (4.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->graphlearning) (1.15.0)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from sklearn->graphlearning) (1.0.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn->graphlearning) (3.1.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn->sklearn->graphlearning) (1.1.0)\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: annoy in /usr/local/lib/python3.7/dist-packages (1.17.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install graphlearning\n",
        "!pip install annoy\n",
        "import numpy as np\n",
        "from scipy.optimize import minimize, LinearConstraint\n",
        "import sklearn.datasets as datasets\n",
        "import graphlearning as gl\n",
        "import matplotlib.pyplot as plt\n",
        "import time, pickle"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "b45424a2",
      "metadata": {
        "id": "b45424a2"
      },
      "outputs": [],
      "source": [
        "\"\"\"\n",
        "Returns the ith vector of the usual basis of R^k\n",
        "Index starts at 0\n",
        "Note: When idx is a (n, ) array (of indices), then it returns\n",
        "an (n, k) array whose j-th row is the idx[j]-th vector of the\n",
        "basis of R^k\n",
        "\n",
        "### Example\n",
        "# print(euclidean_basis(0, 5))\n",
        "# print(euclidean_basis(2, 5))\n",
        "# print(euclidean_basis([0, 2], 5))\n",
        "\"\"\"\n",
        "\n",
        "def save_models(models, filename = \"mnist_models.pickle\"):\n",
        "    with open(filename, 'wb') as f:\n",
        "        pickle.dump(models, f)\n",
        "        f.close()\n",
        "    \n",
        "    return\n",
        "\n",
        "def load_models(filename = \"mnist_models.pickle\"):\n",
        "    with open(filename, \"rb\") as f:\n",
        "        models = pickle.load(f)\n",
        "        f.close()\n",
        "    \n",
        "    return models\n",
        "\n",
        "def euclidean_basis(idx, k):\n",
        "    eye = np.eye(k)\n",
        "    return eye[idx]\n",
        "\n",
        "def vectorized_jacobian(u_flattened, W, idx, y, p):\n",
        "    n = W.shape[0]\n",
        "    k = u_flattened.size//n\n",
        "    m = y.shape[0]    \n",
        "    \n",
        "    u = u_flattened.reshape((n,k))\n",
        "    gradu = graph_grad(u)\n",
        "    normed_gradu = np.apply_along_axis(np.linalg.norm, 2, gradu)\n",
        "    y_bar = y.sum(axis = 0)/m\n",
        "    \n",
        "    if p > 2:\n",
        "        # ... = w*normed_gradu**(p-2)\n",
        "        a1 = W * (normed_gradu**(p-2)) + np.zeros((k, n, n)) # a1[s,i,r] = ...[i, r]\n",
        "        A = np.transpose(a1, (1, 2, 0)) # A[i,r, s] = ...[i, r]\n",
        "\n",
        "        u1 = np.zeros( (n, n, k) ) + u #u1[i, r, s] = u[r, s]\n",
        "\n",
        "        u21 = np.zeros( (n,n,k) ) + u # u21[r, i, s] = u[i, s]\n",
        "        u2 = np.swapaxes(u21, 0, 1) # u2[i, r, s] = u[i, s]\n",
        "\n",
        "        C = u1 - u2\n",
        "\n",
        "        B = np.zeros( (n, k) )\n",
        "        B[idx] = y - y_bar\n",
        "\n",
        "        jac = (A * C).sum(axis = 0) - B\n",
        "    \n",
        "    elif p == 2:\n",
        "        a1 = W + np.zeros((k, n, n)) # a1[s,i,r] = W[i, r]\n",
        "        A = np.transpose(a1, (1, 2, 0)) # A[i, r, s] = W[i, r]\n",
        "        \n",
        "        u1 = np.zeros( (n, n, k) ) + u #u1[i, r, s] = u[r, s]\n",
        "\n",
        "        u21 = np.zeros( (n,n,k) ) + u # u2[r, i, s] = u[i, s]\n",
        "        u2 = np.swapaxes(u21, 0, 1)\n",
        "\n",
        "        C = u1 - u2\n",
        "\n",
        "        B = np.zeros( (n, k) )\n",
        "        B[idx] = y - y_bar\n",
        "            \n",
        "        jac = (A * C).sum(axis = 0) - B\n",
        "    \n",
        "    return jac.flatten()\n",
        "\n",
        "def penergy(u_flattened, W, idx, y, p):\n",
        "    k = y.shape[1]\n",
        "    n = int(u_flattened.size/k)\n",
        "    u = u_flattened.reshape((n,k))\n",
        "    gradu = graph_grad(u)\n",
        "    y_bar = (1/y.shape[0]) * y.sum(axis = 0)\n",
        "    \n",
        "    first_summand = (1/(2*p)) * (W * (np.apply_along_axis(np.linalg.norm, 2, gradu) ** p)).sum()\n",
        "    second_summand = np.sum( (y - y_bar) * u[idx] )\n",
        "\n",
        "    return first_summand - second_summand\n",
        "\n",
        "def graph_grad(u):\n",
        "    gradu = -u[:, np.newaxis] + u\n",
        "    return gradu\n",
        "\n",
        "def degrees(W):\n",
        "    return np.ravel((W.sum(axis = 1)))\n",
        "\n",
        "def predict(u):\n",
        "    return np.argmax(u, axis = 1)\n",
        "    \n",
        "\n",
        "# Solves the p-poisson equation on a graph with weight matrix W\n",
        "# and labels y on the elements with indices idx\n",
        "# using gradient descent\n",
        "def gradient_ppoisson(W, idx, y, p, start = np.zeros(1)):\n",
        "    d = degrees(W)\n",
        "    n = W.shape[0]\n",
        "    k = y.shape[1]\n",
        "    eye = np.eye(k)\n",
        "\n",
        "    labels = predict(y)\n",
        "\n",
        "    if not start.all():\n",
        "        model = gl.ssl.poisson(W, solver='gradient_descent')\n",
        "        start = model.fit(idx, labels).flatten()\n",
        "    \n",
        "    constrain_matrix = np.concatenate([d[i] * eye for i in range(n)], axis = 1)\n",
        "    linear_constraint = LinearConstraint(constrain_matrix, np.zeros(k), np.zeros(k))\n",
        "    \n",
        "    res = minimize(penergy, x0 = start, args = (W, idx, y, p), jac = vectorized_jacobian, method = 'trust-constr', constraints = linear_constraint)\n",
        "    \n",
        "    u = res.x.reshape(n,k)\n",
        "    \n",
        "    return u\n",
        "\n",
        "class ppoisson():\n",
        "    def __init__(self, W, p = 2):\n",
        "        self.W = W\n",
        "        self.p = p\n",
        "        self.solution = None\n",
        "        self.predictions = None\n",
        "        self.runtime = None\n",
        "        \n",
        "    def fit(self, idx, euclidean_labels, start = None):\n",
        "        if not np.array_equiv(self.solution, None):\n",
        "            return self.solution\n",
        "\n",
        "        start_time = time.time()\n",
        "\n",
        "        d = degrees(self.W)\n",
        "        n = self.W.shape[0]\n",
        "        k = euclidean_labels.shape[1]\n",
        "        eye = np.eye(k)\n",
        "\n",
        "        labels = np.argmax(euclidean_labels, axis = 1)\n",
        "\n",
        "        if np.array_equal(start, None):\n",
        "            model = gl.ssl.poisson(self.W, solver='gradient_descent')\n",
        "            start = model.fit(idx, labels).flatten()\n",
        "        \n",
        "        constrain_matrix = np.concatenate([d[i] * eye for i in range(n)], axis = 1)\n",
        "        linear_constraint = LinearConstraint(constrain_matrix, np.zeros(k), np.zeros(k))\n",
        "        \n",
        "        res = minimize(penergy, x0 = start, args = (self.W, idx, euclidean_labels, self.p), jac = vectorized_jacobian, method = 'trust-constr', constraints = linear_constraint)\n",
        "        \n",
        "        u = res.x.reshape(n,k)\n",
        "    \n",
        "        self.solution = u\n",
        "        \n",
        "        end_time = time.time()\n",
        "        self.runtime = (end_time - start_time)/60\n",
        "\n",
        "        return self.solution\n",
        "\n",
        "    def predict(self):\n",
        "        if np.array_equal(self.solution, None):\n",
        "            raise ValueError(\"The model has not been fit yet\")\n",
        "        return np.argmax(self.solution, axis = 1)\n",
        "\n",
        "    def fit_predict(self, idx, euclidean_labels, start = None):\n",
        "        if np.array_equal(self.solution, None):\n",
        "            self.fit(idx, euclidean_labels)\n",
        "            return self.predict()\n",
        "        \n",
        "        return self.predict()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "45fbff1a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45fbff1a",
        "outputId": "09d95277-a6ba-4475-a4f6-076041a92e91"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading https://github.com/jwcalder/GraphLearning/raw/master/Data/MNIST_labels.npz to /content/data/mnist_labels.npz...\n",
            "Downloading http://www-users.math.umn.edu/~jwcalder/Data/MNIST_raw.npz to /content/data/mnist_raw.npz...\n"
          ]
        }
      ],
      "source": [
        "sample_size = 100\n",
        "X,labels = gl.datasets.load('mnist')\n",
        "X = X[:sample_size]\n",
        "labels = labels[:sample_size]\n",
        "\n",
        "W = gl.weightmatrix.knn(X,5).toarray()\n",
        "train_ind = gl.trainsets.generate(labels, rate=3, seed = 1)\n",
        "train_labels = labels[train_ind]\n",
        "euclidean_labels = euclidean_basis(train_labels, 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "158e9a9b",
      "metadata": {
        "id": "158e9a9b"
      },
      "outputs": [],
      "source": [
        "model = gl.ssl.poisson(W, solver='gradient_descent')\n",
        "u = model.fit(train_ind, train_labels)\n",
        "pred_labels = model.predict()\n",
        "\n",
        "pp_model = ppoisson(W, 2)\n",
        "my_pred_labels = pp_model.fit_predict(train_ind, euclidean_labels)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Energy of GraphLearning Solution: %.3f\"%penergy(u.flatten(), W, train_ind, euclidean_labels, 2))\n",
        "print(\"Energy of custom solution: %.3f\"%penergy(pp_model.solution.flatten(), W, train_ind, euclidean_labels, 2))\n",
        "print(\"Accuracy of custom solution: %.2f%%\"%gl.ssl.ssl_accuracy(pp_model.predict(), labels, len(train_ind)))\n",
        "print(\"Accuracy of GraphLearn solution: %.2f%%\"%gl.ssl.ssl_accuracy(pred_labels, labels, len(train_ind)))\n",
        "print(\"Number of different predictions: \", np.count_nonzero(pp_model.predict() - pred_labels))\n",
        "print(\"Runtime of custom solution: %.2fm\"%pp_model.runtime)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1lm4AKDV_Cc3",
        "outputId": "3f6f08d4-2053-4259-ff11-7b0f3267d736"
      },
      "id": "1lm4AKDV_Cc3",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Energy of GraphLearning Solution: -517.487\n",
            "Energy of custom solution: -552.914\n",
            "Accuracy of custom solution: 71.43%\n",
            "Accuracy of GraphLearn solution: 71.43%\n",
            "Number of different predictions:  2\n",
            "Runtime of custom solution: 0.55m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "0e31591d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0e31591d",
        "outputId": "989836df-2247-4c9d-fc0d-e71700319a41"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "########### Gradient Descent (w/ Jacobian) for p = 2\n",
            "Energy = -552.91\n",
            "Discrepancies = 2\n",
            "Accuracy = 71.43%\n",
            "Runtime = 0.46 min\n",
            "########### Gradient Descent (w/ Jacobian) for p = 4\n",
            "Energy = -100.56\n",
            "Discrepancies = 7\n",
            "Accuracy = 67.14%\n",
            "Runtime = 1.29 min\n",
            "########### Gradient Descent (w/ Jacobian) for p = 8\n",
            "Energy = -64.26\n",
            "Discrepancies = 10\n",
            "Accuracy = 67.14%\n",
            "Runtime = 3.03 min\n",
            "########### Gradient Descent (w/ Jacobian) for p = 16\n",
            "Energy = -53.50\n",
            "Discrepancies = 13\n",
            "Accuracy = 64.29%\n",
            "Runtime = 3.02 min\n",
            "########### Gradient Descent (w/ Jacobian) for p = 32\n",
            "Energy = -49.11\n",
            "Discrepancies = 12\n",
            "Accuracy = 65.71%\n",
            "Runtime = 3.04 min\n",
            "########### Gradient Descent (w/ Jacobian) for p = 64\n",
            "Energy = -18.49\n",
            "Discrepancies = 12\n",
            "Accuracy = 65.71%\n",
            "Runtime = 2.91 min\n",
            "########### Gradient Descent (w/ Jacobian) for p = 100\n",
            "Energy = 2289.61\n",
            "Discrepancies = 12\n",
            "Accuracy = 65.71%\n",
            "Runtime = 0.02 min\n",
            "########### Gradient Descent (w/ Jacobian) for p = 110\n",
            "Energy = 8395.03\n",
            "Discrepancies = 12\n",
            "Accuracy = 65.71%\n",
            "Runtime = 0.01 min\n",
            "########### Gradient Descent (w/ Jacobian) for p = 120\n",
            "Energy = 31315.65\n",
            "Discrepancies = 12\n",
            "Accuracy = 65.71%\n",
            "Runtime = 0.01 min\n",
            "########### Gradient Descent (w/ Jacobian) for p = 130\n",
            "Energy = 119316.73\n",
            "Discrepancies = 12\n",
            "Accuracy = 65.71%\n",
            "Runtime = 0.01 min\n",
            "########### Gradient Descent (w/ Jacobian) for p = 140\n",
            "Energy = 463758.92\n",
            "Discrepancies = 12\n",
            "Accuracy = 65.71%\n",
            "Runtime = 0.01 min\n",
            "########### Gradient Descent (w/ Jacobian) for p = 150\n",
            "Energy = 1834415.50\n",
            "Discrepancies = 12\n",
            "Accuracy = 65.71%\n",
            "Runtime = 0.01 min\n",
            "########### Gradient Descent (w/ Jacobian) for p = 160\n",
            "Energy = 7366882.91\n",
            "Discrepancies = 12\n",
            "Accuracy = 65.71%\n",
            "Runtime = 0.01 min\n",
            "########### Gradient Descent (w/ Jacobian) for p = 170\n",
            "Energy = 29973435.47\n",
            "Discrepancies = 12\n",
            "Accuracy = 65.71%\n",
            "Runtime = 0.01 min\n",
            "########### Gradient Descent (w/ Jacobian) for p = 180\n",
            "Energy = 123332146.70\n",
            "Discrepancies = 12\n",
            "Accuracy = 65.71%\n",
            "Runtime = 0.01 min\n",
            "########### Gradient Descent (w/ Jacobian) for p = 190\n",
            "Energy = 512443126.26\n",
            "Discrepancies = 12\n",
            "Accuracy = 65.71%\n",
            "Runtime = 0.01 min\n",
            "########### Gradient Descent (w/ Jacobian) for p = 200\n",
            "Energy = 2147299437.33\n",
            "Discrepancies = 12\n",
            "Accuracy = 65.71%\n",
            "Runtime = 0.01 min\n",
            "########### Gradient Descent (w/ Jacobian) for p = 210\n",
            "Energy = 9064711415.09\n",
            "Discrepancies = 12\n",
            "Accuracy = 65.71%\n",
            "Runtime = 0.01 min\n",
            "########### Gradient Descent (w/ Jacobian) for p = 220\n",
            "Energy = 38515988807.22\n",
            "Discrepancies = 12\n",
            "Accuracy = 65.71%\n",
            "Runtime = 0.01 min\n",
            "########### Gradient Descent (w/ Jacobian) for p = 230\n",
            "Energy = 164598912945.39\n",
            "Discrepancies = 12\n",
            "Accuracy = 65.71%\n",
            "Runtime = 0.01 min\n",
            "########### Gradient Descent (w/ Jacobian) for p = 240\n",
            "Energy = 707027247040.31\n",
            "Discrepancies = 12\n",
            "Accuracy = 65.71%\n",
            "Runtime = 0.01 min\n",
            "########### Gradient Descent (w/ Jacobian) for p = 250\n",
            "Energy = 3050952639437.64\n",
            "Discrepancies = 12\n",
            "Accuracy = 65.71%\n",
            "Runtime = 0.01 min\n",
            "########### Gradient Descent (w/ Jacobian) for p = 260\n",
            "Energy = 13219857892629.14\n",
            "Discrepancies = 12\n",
            "Accuracy = 65.71%\n",
            "Runtime = 0.01 min\n",
            "########### Gradient Descent (w/ Jacobian) for p = 270\n",
            "Energy = 57496433800825.92\n",
            "Discrepancies = 12\n",
            "Accuracy = 65.71%\n",
            "Runtime = 0.02 min\n",
            "########### Gradient Descent (w/ Jacobian) for p = 280\n",
            "Energy = 250918402365759.19\n",
            "Discrepancies = 12\n",
            "Accuracy = 65.71%\n",
            "Runtime = 0.01 min\n",
            "########### Gradient Descent (w/ Jacobian) for p = 290\n",
            "Energy = 1098439245698407.62\n",
            "Discrepancies = 12\n",
            "Accuracy = 65.71%\n",
            "Runtime = 0.01 min\n",
            "########### Gradient Descent (w/ Jacobian) for p = 300\n",
            "Energy = 4822389743861257.00\n",
            "Discrepancies = 12\n",
            "Accuracy = 65.71%\n",
            "Runtime = 0.01 min\n"
          ]
        }
      ],
      "source": [
        "p_vals = [2, 4, 8, 16, 32, 64, 100, 110, 120, 130, 140, 150, 160, 170, 180, 190, 200, 210, 220, 230, 240, 250, 260, 270, 280, 290, 300]\n",
        "k = 10\n",
        "\n",
        "try:\n",
        "    models\n",
        "except:\n",
        "    models = {}\n",
        "else:\n",
        "    pass\n",
        "\n",
        "models['GraphLearning'] = gl.ssl.poisson(W, solver='gradient_descent')\n",
        "u = models['GraphLearning'].fit(train_ind, train_labels)\n",
        "pred_labels = predict(u)\n",
        "my_u = u\n",
        "\n",
        "# Run and plot for varying p\n",
        "for p in p_vals:\n",
        "    models[p] = ppoisson(W, p)\n",
        "    my_u = models[p].fit(train_ind, euclidean_labels, my_u.flatten())\n",
        "    my_pred_labels = models[p].predict()\n",
        "\n",
        "    discrepancies = np.count_nonzero(my_pred_labels - pred_labels)\n",
        "    accuracy = gl.ssl.ssl_accuracy(my_pred_labels, labels, len(train_ind))\n",
        "    energy = np.around(penergy(models[p].solution.flatten(), W, train_ind, euclidean_labels, p), 2)\n",
        "    \n",
        "    info_str = f\"########### Gradient Descent (w/ Jacobian) for p = {p}\\n\"\\\n",
        "                    f\"Energy = {energy:.2f}\\n\"\\\n",
        "                    f\"Discrepancies = {discrepancies}\"\\\n",
        "                    f\"\\nAccuracy = {accuracy:.2f}%\\n\"\\\n",
        "                    f\"Runtime = {models[p].runtime:.2f} min\"\n",
        "\n",
        "    print(info_str)\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(np.linalg.norm(models[300].solution - models[290].solution))\n",
        "print(np.linalg.norm(models[300].solution - models[150].solution))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BiMyE9FANkVa",
        "outputId": "728fe017-fe43-48ce-b2bf-746e139f2203"
      },
      "id": "BiMyE9FANkVa",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.0\n",
            "0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Load models"
      ],
      "metadata": {
        "id": "1_s84z21JDlA"
      },
      "id": "1_s84z21JDlA"
    },
    {
      "cell_type": "code",
      "source": [
        "#load_models()"
      ],
      "metadata": {
        "id": "8IaeR15jJGFa"
      },
      "id": "8IaeR15jJGFa",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Save models"
      ],
      "metadata": {
        "id": "SyYa_aJCJOWl"
      },
      "id": "SyYa_aJCJOWl"
    },
    {
      "cell_type": "code",
      "source": [
        "#save_models(models)"
      ],
      "metadata": {
        "id": "SgfbxcOcJOWp"
      },
      "execution_count": 12,
      "outputs": [],
      "id": "SgfbxcOcJOWp"
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "notify_time": "5",
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}